{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://api.pushshift.io/reddit/'\n",
    "\n",
    "\n",
    "# def request_posts(subreddit, days_ago, base_url=base_url,\n",
    "#                   endpoint='search/submission/', is_video='is_video=false'):\n",
    "#     try:\n",
    "#         response = requests.get(\n",
    "#             f'{base_url}{endpoint}?subreddit={subreddit}&{is_video}&before={days_ago}d&after={days_ago+1}d&size=1000')\n",
    "#         assert response.status_code == 200\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "#     return response\n",
    "\n",
    "\n",
    "# def make_requests(subreddit, days_of_data):\n",
    "#     all_results = []\n",
    "\n",
    "#     for i in range(1, days_of_data):\n",
    "#         try:\n",
    "#             entry = request_posts(subreddit, i)\n",
    "#             all_results.append(pd.DataFrame(entry.json()['data']))\n",
    "#         except:\n",
    "#             pass\n",
    "#         if i % 20 == 0:\n",
    "#             print(f'{i} of {days_of_data} requests completed')\n",
    "#         time.sleep(1.5)\n",
    "\n",
    "#     return pd.concat(all_results)\n",
    "\n",
    "\n",
    "# def request_all_subs(list_of_subreddits, days_of_data):\n",
    "#     all_results = []\n",
    "#     for sub in list_of_subreddits:\n",
    "#         print(f'Querying {sub}...')\n",
    "#         sub_df = make_requests(sub, days_of_data)\n",
    "#         all_results.append(sub_df)\n",
    "#     return pd.concat(all_results)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     subs = ['asoiaf', 'freefolk', 'gameofthrones']\n",
    "#     df = request_all_subs(subs, 100)\n",
    "#     df.to_csv('./data/subreddit_data.csv')\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating API results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This script accepts the raw API response .csv and outputs one with NAs and deleted posts removed,\n",
    "# # plus any HTML fragments removed \n",
    "\n",
    "# # Imports\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import warnings\n",
    "\n",
    "# # Ignore warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Import Data\n",
    "# df = pd.read_csv('../data/subreddit_data.csv')\n",
    "\n",
    "# print('Number of Entries per subreddit pre-cleaning:')\n",
    "# print(df['subreddit'].value_counts())\n",
    "\n",
    "# # Drop posts without selftext\n",
    "# has_self = (df[~df['selftext'].isna()])\n",
    "# has_self = has_self[has_self['domain'].str.contains('self')]\n",
    "\n",
    "# # Drop posts where text has been removed or deleted by users/moderators\n",
    "# has_self = has_self[has_self['selftext']!='[removed]']\n",
    "# has_self = has_self[has_self['selftext']!='[deleted]']\n",
    "# has_self = has_self[~has_self['selftext'].str.startswith('[removed]')]\n",
    "# has_self = has_self[~has_self['selftext'].str.startswith('[deleted]')]\n",
    "\n",
    "# # Select the columns we're interested in modeling\n",
    "# columns = ['author', 'full_link', 'id', 'num_comments', 'num_crossposts', 'over_18',\n",
    "#                      'spoiler', 'subreddit', 'title', 'total_awards_received', 'upvote_ratio',\n",
    "#                      'edited', 'gilded','selftext']\n",
    "\n",
    "# has_self = has_self[columns]\n",
    "\n",
    "# # Reset index of results because it is annoying \n",
    "# has_self.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print('Number of Entries per subreddit post-cleaning:')\n",
    "# print(has_self['subreddit'].value_counts())\n",
    "\n",
    "# # Just in case there are any HTML impurities in the raw data, we will use BeautifulSoup \n",
    "# # to clean the text columns\n",
    "# for col in has_self:\n",
    "#     if has_self[col].dtypes == 'O':\n",
    "#         for item in has_self.index:\n",
    "#             has_self.loc[item,col] = BeautifulSoup(has_self.loc[item,col]).get_text()\n",
    "\n",
    "# has_self.to_csv('../data/cleaned_subreddit_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating our full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Craig\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,1,4,6,7,8,9,10,11,16,18,19,20,21,22,25,27,28,30,31,33,34,40,45,51,55,60,63,64,65,66,67,71,72,73,78,79,81,82,84,86,89,90,91,92,94,97,98,100,101,102,103,104,108,109) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_csv('../data/subreddit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','selftext','author','title','subreddit']\n",
    "\n",
    "raw = raw[columns]\n",
    "\n",
    "raw.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6         What is the Most and Least Knightly Acts in AS...\n",
       "155        Recently I have completed a portion of my big...\n",
       "322       Brienne. People always praise GRRM for writing...\n",
       "358       A Storm of Sword was more interesting for me t...\n",
       "419       There are lots of theories on the identity of ...\n",
       "                                ...                        \n",
       "234791    Strange thing with Sansa's wedding scene i spo...\n",
       "234870    https://en.m.wikipedia.org/wiki/Damascus_steel...\n",
       "237610    Why was Jon Snow given the name Snow?\\n\\nI tho...\n",
       "241723    So, Joffrey is poisoned with a drink by Olenna...\n",
       "242867    In season 3 episode 6 Melisandre says: \"I see ...\n",
       "Name: selftext, Length: 765, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[raw['selftext'].str.contains(\"\\xa0\")]['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155     Recently I have completed a portion of my big...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.loc[155:157,'selftext'].str.replace('\\xa0',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the Most and Least Knightly Acts in ASOIAF in your opinion?\\n\\nMy most knightly act of the series is an ironic choice because the deed is done by Brienne of Tarth, who honored her vow to protect the weak, by defending the orphans from some of Westero\\'s worst monsters. Compare her act to the Knight of Saltpans who sat in his castle, as \"The Hound\" ravages the town. Brienne is the definition of a knight. A close second is a minor, yet gallant act. During the wedding between Sansa Stark and Tyrion Lannister, Ser Garland is one of\\xa0the few people who is actually nice to Sansa, and his dance with the terrified, young maid is the highlight of her night. Ser Garland is similarly kind to Tyrion, and goes so far to defend him in front of the Incest King.\\n\\nMy least knightly act of the series, would probably be Ser Gregor\\'s brutal campaign throughout the Riverlands, which featured such atrocities as rape, torture, and forced auto-cannibalism. Compare this with Ser Arthur\\'s Dayne campaign throughout the Kingswood.\\n\\nI was tempted to list Ser Quincy Cox as least cowardly act, and while cowardice is generally a bad trait for a knight, sadism is much worse. One of my favorite themes in ASOIAF is how many of the characters who exhibit knightly qualities are not actually knights. Examples of this are Brienne of Tarth, Sandor Clegane, and \"Ser\" Duncan the Tall.\\xa0'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.loc[6,'selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&gt;If  I had been a better knight… if I had unhorsed the prince in that last  tilt, as I unhorsed so many others, it would have been for me to choose  the queen of love and beauty…\\n\\nBarristan lost to Rhaegar during the tourney at Harrenhal:\\n\\n&gt;Prince  Rhaegar emerged as the ultimate victor at the end of the  competition.  The crown prince, who did not normally compete in tourneys,  surprised  all by donning his armor and defeating every foe he faced, including  four knights of the Kingsguard. In the final tilt, he unhorsed Ser  Barristan Selmy, generally regarded as the finest lance in all the Seven  Kingdoms, to win the champion\\'s laurels.\\n\\nSo  Rhaegar, who \"did not normally compete in tourneys\" manages to beat  \"the finest lance in the realm\". Not only that, but he also defeats  three other members of the Kingsguard (possibly Arthur Dayne, Lewyn  Martell, and Oswell Whent?).\\n\\nBarristan  doesn\\'t say \"If I had been a better jouster\", he says he should have  been \"a better knight\". In his mind, knighthood doesn\\'t equate with  skill at arms, but with honor:\\n\\n&gt;Who are you, old man?  \\n\"A better knight than you, ser,\" Arstan said coldly.\\n\\nHe  thinks himself a better knight than Jorah, because he\\'s more honorable -  he knows that Jorah was feeding information on Dany to Varys.\\n\\nAnd  he didn\\'t live up to the moral values of knighthood at Harrenhal,  because he lost on purpose to Rhaegar. Like all sporting events in our  world, tourneys are fixed in Westeros, and Barristan sold his soul on  this particular occasion.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.loc[28,'selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28     If  I had been a better knight… if I had unho...\n",
       "29    Since I have PTSD from the Red Wedding, I’m th...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.loc[28:29,'selftext'].str.replace('&gt;',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform, loguniform\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "#import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed_subreddit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70985, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70985, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['For', 'me', 'it', 'is', 'Jon', 'Snow', 'He', 'used', 'to', 'be', 'my', 'favorite', 'but', 'the', 'overpandering', 'to', 'his', 'character', 'by', 'saying', 'he', 'is', 'the', 'subject', 'to', 'every', 'prophecy', 'and', 'is', 'basically', 'Jesus', 'is', 'so', 'annoying', 'He', 'is', 'still', 'a', 'good', 'character', 'especially', 'in', 'the', 'book', 'but', 'thinking', 'jon', 'snow', 'will', 'defeat', 'the', 'other', 'then', 'he', 'will', 'kill', 'dany', 'and', 'then', 'rule', 'wisely', 'and', 'justly', 'because', 'he', 'is', 'the', 'perfect', 'hero', 'is', 'annoying']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selftext[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(df[df['author'] == 'AutoModerator'].index)\n",
    "\n",
    "#  df.loc[:,'selftext'] = df['selftext'].str.replace('x200B','')\n",
    "\n",
    "#  df.loc[:,'selftext'] = df['selftext'].str.replace('\\n',' ')\n",
    "\n",
    "# df = df[~df['selftext'].isna()]\n",
    "\n",
    "# df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'index', 'id', 'selftext', 'author', 'title', 'subreddit'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70985, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_authors = df.author.value_counts().sort_values(ascending=False).head(21).index[1:]\n",
    "\n",
    "# table = df.loc[df['author'].isin(most_common_authors),['author','subreddit','id']].groupby(['author','subreddit']).count()\n",
    "\n",
    "# table.index.levels\n",
    "\n",
    "# ax = table.unstack().plot.barh(figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8        ['As', 'you', 'know', 'GRRM', 'made', 'a', 'st...\n",
       "11       ['gtIf', 'I', 'had', 'been', 'a', 'better', 'k...\n",
       "12       ['Since', 'I', 'have', 'PTSD', 'from', 'the', ...\n",
       "13       ['From', 'JonCon', 'in', 'ADWD', 'gt', 'He', '...\n",
       "15       ['There', 'is', 'a', 'number', 'of', 'fact', '...\n",
       "                               ...                        \n",
       "70869    ['Long', 'post', 'Lets', 'walk', 'through', 's...\n",
       "70872    ['When', 'i', 'saw', 'the', 'scene', 'with', '...\n",
       "70899    ['Look', 'I', 'know', 'nobody', 'liked', 'Ella...\n",
       "70900    ['Ive', 'seen', 'quite', 'a', 'few', 'people',...\n",
       "70913    ['John', 'left', 'Winterfell', 'and', 'everyon...\n",
       "Name: selftext, Length: 7702, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['selftext'].str.contains(\"gt\")]['selftext']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['gtIf', 'I', 'had', 'been', 'a', 'better', 'knight…', 'if', 'I', 'had', 'unhorsed', 'the', 'prince', 'in', 'that', 'last', 'tilt', 'a', 'I', 'unhorsed', 'so', 'many', 'others', 'it', 'would', 'have', 'been', 'for', 'me', 'to', 'choose', 'the', 'queen', 'of', 'love', 'and', 'beauty…', 'Barristan', 'lost', 'to', 'Rhaegar', 'during', 'the', 'tourney', 'at', 'Harrenhal', 'gtPrince', 'Rhaegar', 'emerged', 'a', 'the', 'ultimate', 'victor', 'at', 'the', 'end', 'of', 'the', 'competition', 'The', 'crown', 'prince', 'who', 'did', 'not', 'normally', 'compete', 'in', 'tourney', 'surprised', 'all', 'by', 'donning', 'his', 'armor', 'and', 'defeating', 'every', 'foe', 'he', 'faced', 'including', 'four', 'knight', 'of', 'the', 'Kingsguard', 'In', 'the', 'final', 'tilt', 'he', 'unhorsed', 'Ser', 'Barristan', 'Selmy', 'generally', 'regarded', 'a', 'the', 'finest', 'lance', 'in', 'all', 'the', 'Seven', 'Kingdoms', 'to', 'win', 'the', 'champion', 'laurel', 'So', 'Rhaegar', 'who', 'did', 'not', 'normally', 'compete', 'in', 'tourney', 'manages', 'to', 'beat', 'the', 'finest', 'lance', 'in', 'the', 'realm', 'Not', 'only', 'that', 'but', 'he', 'also', 'defeat', 'three', 'other', 'member', 'of', 'the', 'Kingsguard', 'possibly', 'Arthur', 'Dayne', 'Lewyn', 'Martell', 'and', 'Oswell', 'Whent', 'Barristan', 'doesnt', 'say', 'If', 'I', 'had', 'been', 'a', 'better', 'jouster', 'he', 'say', 'he', 'should', 'have', 'been', 'a', 'better', 'knight', 'In', 'his', 'mind', 'knighthood', 'doesnt', 'equate', 'with', 'skill', 'at', 'arm', 'but', 'with', 'honor', 'gtWho', 'are', 'you', 'old', 'man', 'A', 'better', 'knight', 'than', 'you', 'ser', 'Arstan', 'said', 'coldly', 'He', 'think', 'himself', 'a', 'better', 'knight', 'than', 'Jorah', 'because', 'he', 'more', 'honorable', 'he', 'know', 'that', 'Jorah', 'wa', 'feeding', 'information', 'on', 'Dany', 'to', 'Varys', 'And', 'he', 'didnt', 'live', 'up', 'to', 'the', 'moral', 'value', 'of', 'knighthood', 'at', 'Harrenhal', 'because', 'he', 'lost', 'on', 'purpose', 'to', 'Rhaegar', 'Like', 'all', 'sporting', 'event', 'in', 'our', 'world', 'tourney', 'are', 'fixed', 'in', 'Westeros', 'and', 'Barristan', 'sold', 'his', 'soul', 'on', 'this', 'particular', 'occasion']\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[11,'selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['There', 'is', 'a', 'number', 'of', 'fact', 'we', 'can', 'be', 'sure', 'of', 'concerning', 'Danys', 'origin', 'Fact', '1', 'Rhaella', 'gave', 'birth', 'to', 'a', 'girl', 'named', 'Daenerys', 'on', 'Dragonstone', 'How', 'can', 'we', 'certain', 'of', 'that', 'Because', 'of', 'this', 'statement', 'amp', 'gt', 'That', 'may', 'be', 'Or', 'not', 'Kevan', 'Lannister', 'had', 'been', 'here', 'in', 'this', 'very', 'hall', 'when', 'Tywin', 'had', 'laid', 'the', 'body', 'of', 'Prince', 'Rhaegars', 'child', 'at', 'the', 'foot', 'of', 'the', 'Iron', 'Throne', 'wrapped', 'up', 'in', 'crimson', 'cloak', 'The', 'girl', 'had', 'been', 'recognizably', 'the', 'Princess', 'Rhaenys', 'but', 'the', 'boy', '…', 'a', 'faceless', 'horror', 'of', 'bone', 'and', 'brain', 'and', 'gore', 'a', 'few', 'hank', 'of', 'fair', 'hair', 'None', 'of', 'u', 'looked', 'long', 'Tywin', 'said', 'that', 'it', 'wa', 'Prince', 'Aegon', 'and', 'we', 'took', 'him', 'at', 'his', 'word', 'We', 'have', 'these', 'tale', 'coming', 'from', 'the', 'east', 'a', 'well', 'A', 'second', 'Targaryen', 'and', 'one', 'whose', 'blood', 'no', 'man', 'can', 'question', 'Daenerys', 'Stormborn', 'While', 'this', 'statement', 'alone', 'doe', 'not', 'prove', 'Dany', 'is', 'this', 'Daenerys', 'we', 'can', 'be', 'sure', 'that', 'there', 'wa', 'a', 'Daenerys', 'born', 'on', 'Dragonstone', 'The', 'small', 'council', 'may', 'not', 'have', 'the', 'the', 'cleverest', 'mind', 'but', 'for', 'them', 'to', 'consider', 'Daenerys', 'blood', 'to', 'be', 'beyond', 'question', 'mean', 'that', 'this', 'birth', 'is', 'extremely', 'well', 'established', 'Dragonstone', 'is', 'big', 'island', 'with', 'thousand', 'of', 'potential', 'witness', 'of', 'this', 'birth', 'and', 'Rhaellas', 'pregnancy', 'The', 'garnison', 'the', 'servant', 'the', 'maester', 'the', 'midwife', 'the', 'crew', 'of', 'the', 'Targaryen', 'fleet', 'the', 'smallfolks', 'including', 'the', 'familly', 'who', 'provided', 'the', 'wetnurse', 'for', 'Daenerys', 'For', 'the', 'small', 'council', 'to', 'consider', 'Daenerys', 'blood', 'to', 'be', 'beyond', 'question', 'mean', 'that', 'when', 'Stannis', 'took', 'the', 'island', 'the', 'first', 'thing', 'he', 'did', 'wa', 'ask', 'where', 'are', 'the', 'Targaryen', 'and', 'everybody', 'there', 'told', 'him', 'that', 'Rhaella', 'died', 'giving', 'birth', 'to', 'a', 'girl', 'she', 'named', 'Daenerys', 'during', 'that', 'storm', 'and', 'that', 'Willem', 'Darry', 'fled', 'with', 'this', 'child', 'and', 'Viserys', 'Which', 'he', 'did', 'amp', 'gtI', 'built', 'a', 'fleet', 'at', 'Roberts', 'command', 'took', 'Dragonstone', 'in', 'his', 'name', 'Did', 'he', 'take', 'my', 'hand', 'and', 'say', 'Well', 'done', 'brother', 'whatever', 'should', 'I', 'do', 'without', 'you', 'No', 'he', 'blamed', 'me', 'for', 'letting', 'Willem', 'Darry', 'steal', 'away', 'Viserys', 'and', 'the', 'babe', 'a', 'if', 'I', 'could', 'have', 'stopped', 'it', 'If', 'this', 'birth', 'did', 'not', 'happened', 'it', 'mean', 'hundred', 'of', 'people', 'no', 'longer', 'loyal', 'to', 'the', 'Targaryen', 'lied', 'to', 'Stannis', 'about', 'it', 'without', 'any', 'reason', 'and', 'all', 'kept', 'their', 'story', 'straight', 'for', 'a', 'decade', 'amp', 'Fact', '2', 'Daenerys', 'wa', 'born', 'during', 'a', 'storm', 'How', 'can', 'we', 'certain', 'of', 'that', 'Again', 'because', 'of', 'this', 'statement', 'amp', 'gt', 'That', 'may', 'be', 'Or', 'not', 'Kevan', 'Lannister', 'had', 'been', 'here', 'in', 'this', 'very', 'hall', 'when', 'Tywin', 'had', 'laid', 'the', 'body', 'of', 'Prince', 'Rhaegars', 'child', 'at', 'the', 'foot', 'of', 'the', 'Iron', 'Throne', 'wrapped', 'up', 'in', 'crimson', 'cloak', 'The', 'girl', 'had', 'been', 'recognizably', 'the', 'Princess', 'Rhaenys', 'but', 'the', 'boy', '…', 'a', 'faceless', 'horror', 'of', 'bone', 'and', 'brain', 'and', 'gore', 'a', 'few', 'hank', 'of', 'fair', 'hair', 'None', 'of', 'u', 'looked', 'long', 'Tywin', 'said', 'that', 'it', 'wa', 'Prince', 'Aegon', 'and', 'we', 'took', 'him', 'at', 'his', 'word', 'We', 'have', 'these', 'tale', 'coming', 'from', 'the', 'east', 'a', 'well', 'A', 'second', 'Targaryen', 'and', 'one', 'whose', 'blood', 'no', 'man', 'can', 'question', 'Daenerys', 'Stormborn', 'Why', 'do', 'they', 'call', 'her', 'Stormborn', 'and', 'consider', 'her', 'blood', 'to', 'beyond', 'question', 'if', 'they', 'were', 'no', 'storm', 'If', 'Dany', 'is', 'fake', 'wouldnt', 'calling', 'her', 'Stormborn', 'blew', 'her', 'cover', 'The', 'Stormborn', 'name', 'is', 'part', 'of', 'the', 'official', 'Daenerys', 'Targaryen', 'identity', 'In', 'other', 'word', 'if', 'Dany', 'is', 'a', 'fake', 'Daenerys', 'she', 'is', 'also', 'a', 'fake', 'Stormborn', 'amp', 'Fact', '3', 'Dany', 'and', 'Viserys', 'were', 'together', 'at', 'the', 'house', 'with', 'the', 'red', 'door', 'How', 'can', 'we', 'know', 'that', 'Because', 'of', 'this', 'gtThat', 'wa', 'when', 'they', 'lived', 'in', 'Braavos', 'in', 'the', 'big', 'house', 'with', 'the', 'red', 'door', 'Dany', 'had', 'her', 'own', 'room', 'there', 'with', 'a', 'lemon', 'tree', 'outside', 'her', 'window', 'After', 'Ser', 'Willem', 'had', 'died', 'the', 'servant', 'had', 'stolen', 'what', 'little', 'money', 'they', 'had', 'left', 'and', 'soon', 'after', 'they', 'had', 'been', 'put', 'out', 'of', 'the', 'big', 'house', 'Dany', 'had', 'cried', 'when', 'the', 'red', 'door', 'closed', 'behind', 'them', 'forever', 'Who', 'is', 'they', 'them', 'if', 'Viserys', 'wa', 'not', 'there', 'amp', 'gtDany', 'had', 'only', 'meant', 'their', 'room', 'in', 'Illyrios', 'estate', 'no', 'true', 'home', 'surely', 'though', 'all', 'they', 'had', 'but', 'her', 'brother', 'did', 'not', 'want', 'to', 'hear', 'that', 'There', 'wa', 'no', 'home', 'there', 'for', 'him', 'Even', 'the', 'big', 'house', 'with', 'the', 'red', 'door', 'had', 'not', 'been', 'home', 'for', 'him', 'Why', 'would', 'Dany', 'think', 'that', 'the', 'house', 'with', 'the', 'red', 'door', 'wa', 'not', 'a', 'home', 'for', 'Viserys', 'if', 'he', 'wa', 'not', 'there', 'More', 'importantly', 'Dany', 'never', 'mention', 'metting', 'Viserys', 'She', 'would', 'definitly', 'remember', 'that', 'especially', 'if', 'it', 'happened', 'after', 'leaving', 'the', 'house', 'with', 'the', 'red', 'door', 'This', 'mean', 'Dany', 'ha', 'been', 'with', 'Viserys', 'all', 'her', 'life', 'amp', 'Fact', '4', 'Viserys', 'genuinely', 'believed', 'Dany', 'to', 'be', 'his', 'sister', 'How', 'can', 'we', 'certain', 'of', 'that', 'Because', 'of', 'these', 'statement', 'gt', 'Her', 'mother', 'had', 'died', 'birthing', 'her', 'and', 'for', 'that', 'her', 'brother', 'Viserys', 'had', 'never', 'forgiven', 'her', 'amp', 'gt', 'Once', 'on', 'a', 'voyage', 'to', 'Braavos', 'a', 'shed', 'watched', 'the', 'crew', 'wrestle', 'down', 'a', 'great', 'green', 'sail', 'in', 'a', 'rising', 'gale', 'she', 'had', 'even', 'thought', 'how', 'fine', 'it', 'would', 'be', 'to', 'be', 'a', 'sailor', 'But', 'when', 'she', 'told', 'her', 'brother', 'Viserys', 'had', 'twisted', 'her', 'hair', 'until', 'she', 'cried', 'You', 'are', 'blood', 'of', 'the', 'dragon', 'he', 'had', 'screamed', 'at', 'her', 'A', 'dragon', 'not', 'some', 'smelly', 'fish', 'amp', 'gt', 'Dany', 'pulled', 'the', 'lion', 'pelt', 'tighter', 'about', 'her', 'shoulder', 'Viserys', 'said', 'once', 'that', 'it', 'wa', 'my', 'fault', 'for', 'being', 'born', 'too', 'late', 'She', 'had', 'denied', 'it', 'hotly', 'she', 'remembered', 'going', 'so', 'far', 'a', 'to', 'tell', 'Viserys', 'that', 'it', 'wa', 'his', 'fault', 'for', 'not', 'being', 'born', 'a', 'girl', 'He', 'beat', 'her', 'cruelly', 'for', 'that', 'insolence', 'amp', 'Are', 'these', 'Viserys', 'lying', 'to', 'Dany', 'Viserys', 'the', 'beggar', 'king', 'the', 'sorefoot', 'king', 'Khal', 'Rhaggat', 'the', 'guy', 'who', 'draw', 'a', 'blade', 'in', 'Vaes', 'Dothrak', 'And', 'he', 'would', 'have', 'started', 'doing', 'that', 'when', 'he', 'wa', 'still', 'a', 'child', 'in', 'the', 'house', 'with', 'the', 'red', 'door', 'amp', 'We', 'can', 'be', 'certain', 'that', 'Rhaella', 'gave', 'birth', 'to', 'a', 'girl', 'Daenerys', 'Darry', 'took', 'this', 'Daenerys', 'and', 'Viserys', 'to', 'the', 'house', 'with', 'the', 'red', 'door', 'Viserys', 'believed', 'Dany', 'to', 'be', 'Daenerys', 'Therefore', 'Dany', 'Daenerys', 'amp', 'What', 'about', 'Lemongate', 'So', 'the', 'ONLY', 'weird', 'thing', 'about', 'Dany', 'story', 'is', 'the', 'lemon', 'tree', 'when', 'there', 'is', 'no', 'lemon', 'tree', 'in', 'Braavos', 'And', 'GRRM', 'said', 'a', 'few', 'thing', 'about', 'it', 'So', 'maybe', 'there', 'is', 'more', 'to', 'Dany', 'story', 'that', 'we', 'know', 'Possible', 'answer', 'Darry', 'take', 'Dany', 'and', 'Viserys', 'to', 'Braavos', 'There', 'Oberyn', 'show', 'up', 'sign', 'the', 'marriage', 'pact', 'and', 'take', 'the', 'Targaryen', 'kid', 'with', 'him', 'to', 'Dorne', 'without', 'telling', 'Viserys', 'where', 'they', 'are', 'Then', 'Darry', 'died', 'Viserys', 'hit', 'puberty', 'and', 'the', 'Martell', 'give', 'up', 'on', 'him', 'or', 'Viserys', 'decided', 'to', 'do', 'his', 'own', 'thing', 'and', 'look', 'for', 'support', 'accross', 'the', 'free', 'city', 'However', 'keep', 'in', 'mind', 'Fact', '5', 'amp', 'Fact', '5', 'Dany', 'ha', 'been', 'to', 'Braavos', 'several', 'time', 'amp', 'gtOnce', 'on', 'a', 'voyage', 'to', 'Braavos', 'a', 'shed', 'watched', 'the', 'crew', 'wrestle', 'down', 'a', 'great', 'green', 'sail', 'in', 'a', 'rising', 'gale', 'she', 'had', 'even', 'thought', 'how', 'fine', 'it', 'would', 'be', 'to', 'be', 'a', 'sailor', 'But', 'when', 'she', 'told', 'her', 'brother', 'Viserys', 'had', 'twisted', 'her', 'hair', 'until', 'she', 'cried', 'You', 'are', 'blood', 'of', 'the', 'dragon', 'he', 'had', 'screamed', 'at', 'her', 'A', 'dragon', 'not', 'some', 'smelly', 'fish', 'Dany', 'remember', 'one', 'voyage', 'to', 'Braavos', 'implying', 'there', 'wa', 'others', 'So', 'if', 'Braavos', 'is', 'not', 'the', 'place', 'she', 'remember', 'when', 'thinking', 'about', 'the', 'house', 'with', 'the', 'red', 'door', 'she', 'had', 'the', 'opportunity', 'to', 'find', 'out', 'amp', 'gt', 'Seven', 'hell', 'this', 'place', 'is', 'damp', 'she', 'heard', 'her', 'guard', 'complain', 'Im', 'chilled', 'to', 'the', 'bone', 'Where', 'are', 'the', 'bloody', 'orange', 'tree', 'I', 'always', 'heard', 'there', 'were', 'orange', 'tree', 'in', 'the', 'Free', 'Cities', 'Lemons', 'and', 'lime', 'Pomegranates', 'Hot', 'pepper', 'warm', 'night', 'girl', 'with', 'bare', 'belly', 'Where', 'are', 'the', 'barebellied', 'girl', 'I', 'ask', 'you', 'gt', 'gtDown', 'in', 'Lys', 'and', 'Myr', 'and', 'Old', 'Volantis', 'the', 'other', 'guard', 'replied', 'He', 'wa', 'an', 'older', 'man', 'bigbellied', 'and', 'grizzled', 'I', 'went', 'to', 'Lys', 'with', 'Lord', 'Tywin', 'once', 'when', 'he', 'wa', 'Hand', 'to', 'Aerys', 'Braavos', 'is', 'north', 'of', 'Kings', 'Landing', 'fool', 'Cant', 'you', 'read', 'a', 'bloody', 'map', 'So', 'maybe', 'here', 'GRRM', 'is', 'making', 'a', 'joke', 'about', 'himself']\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[15,'selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_reddit = TfidfVectorizer(lowercase=True, stop_words='english',\n",
    "                              ngram_range=(1,2),max_df=.95, min_df=3, max_features=5000)\n",
    "\n",
    "vect_table = tfid_reddit.fit_transform(df['selftext'])\n",
    "\n",
    "vect_df = pd.DataFrame(vect_table.toarray(), columns = tfid_reddit.get_feature_names())\n",
    "\n",
    "vect_df_sorted = vect_df.sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "door hold         2.418168\n",
       "gt arya           6.544665\n",
       "serra             6.920188\n",
       "lewyn             7.282225\n",
       "ampnbsp house     7.289751\n",
       "black eye         7.451584\n",
       "xii               7.573839\n",
       "elder brother     7.775377\n",
       "gtbran            8.456489\n",
       "shadrich          8.874994\n",
       "gtbut             8.912504\n",
       "daenerys iv       8.959781\n",
       "gt tyrion         9.019384\n",
       "agot gt           9.047674\n",
       "gtas              9.072678\n",
       "mouse             9.149530\n",
       "hosteen           9.205317\n",
       "prey              9.255739\n",
       "hypothesis        9.282239\n",
       "gtmy              9.287901\n",
       "amethyst          9.358661\n",
       "xi                9.385269\n",
       "sealord           9.585352\n",
       "gtlord            9.696330\n",
       "asharas           9.774302\n",
       "brow              9.789419\n",
       "informs           9.834322\n",
       "aeryss            9.932858\n",
       "gthis             9.958318\n",
       "oak               9.964327\n",
       "bran iii          9.966074\n",
       "cok              10.024826\n",
       "echo             10.097865\n",
       "robe             10.449931\n",
       "gtser            10.586942\n",
       "ty               10.597682\n",
       "vanished         10.599697\n",
       "gtif             10.661271\n",
       "rhyme            10.698713\n",
       "divine           10.723322\n",
       "ffc              10.754653\n",
       "oswell           10.783050\n",
       "thigh            10.850351\n",
       "gtthere          10.888276\n",
       "ariannes         10.967770\n",
       "poured           11.065037\n",
       "quentyns         11.086497\n",
       "shouted          11.124808\n",
       "glanced          11.254310\n",
       "begged           11.322052\n",
       "howling          11.335993\n",
       "copper           11.378358\n",
       "born amidst      11.452059\n",
       "adwd tyrion      11.464803\n",
       "ordinary         11.619095\n",
       "kindly man       11.637582\n",
       "trench           11.650208\n",
       "brandons         11.665029\n",
       "hollow           11.683235\n",
       "let look         11.701206\n",
       "brushed          11.707195\n",
       "ser ilyn         11.841007\n",
       "gtthey           11.917092\n",
       "slender          11.945131\n",
       "horn winter      11.985133\n",
       "mentor           12.003590\n",
       "faded            12.022445\n",
       "gerion           12.036437\n",
       "smelled          12.052596\n",
       "alyn             12.128138\n",
       "lightly          12.134746\n",
       "fourteen         12.154294\n",
       "aurane           12.197671\n",
       "shaggy           12.198756\n",
       "glow             12.212465\n",
       "lord stark       12.213278\n",
       "gttyrion         12.230457\n",
       "nurse            12.260376\n",
       "precisely        12.305272\n",
       "gtthat           12.309993\n",
       "weeping          12.340705\n",
       "amp gt           12.343980\n",
       "climbed          12.368397\n",
       "sos              12.405220\n",
       "frightened       12.495893\n",
       "longsword        12.504143\n",
       "sphinx           12.510744\n",
       "seated           12.515656\n",
       "ser duncan       12.544004\n",
       "ssm              12.548935\n",
       "softly           12.556703\n",
       "studied          12.565119\n",
       "bleed            12.578714\n",
       "approached       12.591831\n",
       "great hall       12.616455\n",
       "wa prince        12.619363\n",
       "wake dragon      12.632257\n",
       "muscle           12.633437\n",
       "taller           12.643675\n",
       "balons           12.657886\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_df_sorted.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seen           471.516653\n",
       "world          472.115490\n",
       "army           477.671160\n",
       "die            480.010692\n",
       "hand           481.007562\n",
       "look           486.655323\n",
       "ending         486.723232\n",
       "killed         489.722943\n",
       "snow           492.211262\n",
       "life           493.072110\n",
       "grrm           494.392524\n",
       "thats          496.473927\n",
       "kings          496.990277\n",
       "actually       499.432697\n",
       "war            506.915709\n",
       "new            510.390938\n",
       "targaryen      512.961710\n",
       "men            515.155005\n",
       "lot            520.246303\n",
       "point          525.676389\n",
       "stannis        530.787598\n",
       "great          530.937690\n",
       "man            532.250413\n",
       "white          536.020936\n",
       "doesnt         536.520689\n",
       "guy            540.916167\n",
       "long           543.657526\n",
       "right          546.083823\n",
       "night king     565.276823\n",
       "feel           570.033149\n",
       "mean           574.035884\n",
       "dead           576.166780\n",
       "battle         578.298237\n",
       "north          581.082718\n",
       "winterfell     582.842557\n",
       "westeros       585.101063\n",
       "watch          586.700209\n",
       "gt             586.743784\n",
       "child          597.214048\n",
       "death          598.947063\n",
       "doe            617.187453\n",
       "didnt          619.008242\n",
       "year           625.569325\n",
       "read           627.227915\n",
       "wall           627.981785\n",
       "maybe          631.353551\n",
       "theory         639.546571\n",
       "said           641.588923\n",
       "kill           647.154714\n",
       "ive            653.241422\n",
       "lord           657.762229\n",
       "throne         664.685081\n",
       "stark          664.878018\n",
       "daenerys       668.301616\n",
       "ned            670.941984\n",
       "love           672.233418\n",
       "scene          674.892678\n",
       "house          675.855115\n",
       "come           682.178457\n",
       "game           682.863889\n",
       "good           719.440442\n",
       "series         742.125750\n",
       "jaime          743.389624\n",
       "going          743.924095\n",
       "thought        746.647540\n",
       "story          771.157568\n",
       "want           784.879559\n",
       "sansa          790.135687\n",
       "thing          791.416465\n",
       "way            806.717876\n",
       "say            835.080841\n",
       "night          842.502973\n",
       "end            849.600001\n",
       "really         887.585284\n",
       "arya           901.332739\n",
       "make           914.026273\n",
       "tyrion         940.476675\n",
       "cersei         951.226704\n",
       "bran           953.505732\n",
       "episode        958.955930\n",
       "got            960.935156\n",
       "dont           981.443817\n",
       "people         994.005541\n",
       "did           1008.652978\n",
       "dragon        1039.035237\n",
       "dany          1054.071832\n",
       "time          1121.093127\n",
       "character     1175.583041\n",
       "king          1259.776021\n",
       "im            1308.041005\n",
       "amp           1313.697929\n",
       "ha            1419.058006\n",
       "book          1426.804825\n",
       "know          1493.367600\n",
       "season        1639.419321\n",
       "like          1689.265613\n",
       "think         1731.655540\n",
       "just          1819.008677\n",
       "jon           1850.932569\n",
       "wa            2923.569895\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_df_sorted.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df['subreddit'] = df['subreddit']\n",
    "vect_df['selftext'] = df['selftext']\n",
    "\n",
    "vect_df[vect_df['subreddit'] == 'freefolk'].drop(columns='subreddit').sum().sort_values(ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df[vect_df['subreddit'] == 'gameofthrones'].drop(columns='subreddit').sum().sort_values(ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_df[vect_df['subreddit'] == 'asoiaf'].drop(columns='subreddit').sum().sort_values(ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Like yes I know you get Theons internal monologues and such is the book but I feel hes a lot more sympathetic and emotional in the show Alfie Allen does a fantastic job and you really see the conflict in his acting and his regret for what hes done Maester Luwin too i feel is a lot better and Rodriks death is definitely more impactful in the show than the book'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[45,'selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing workflow:\n",
    "\n",
    "- tokenize\n",
    "- remove stopwords\n",
    "- lemmatize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'] = [word_tokenize(str(text)) for text in df['selftext']]\n",
    "\n",
    "df['title'] = [word_tokenize(str(text)) for text in df['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'church'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('churches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'] = [[lemmatizer.lemmatize(word) for word in text] for text in df['selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext'] = [' '.join([stemmer.stem(word) for word in text]) for text in df['selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for me it is jon snow He use to be my favorit but the overpand to hi charact by say he is the subject to everi propheci and is basic jesu is so annoy He is still a good charact especi in the book but think jon snow will defeat the other then he will kill dani and then rule wise and justli becaus he is the perfect hero is annoy'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selftext[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(frac=.05)\n",
    "\n",
    "sample.subreddit.value_counts()\n",
    "\n",
    "sample.subreddit.value_counts(normalize=True)\n",
    "\n",
    "sample.shape\n",
    "\n",
    "X = sample['selftext']\n",
    "y = sample['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfid_final_params = {'tfid__max_df': 0.325,\n",
    "#   'tfid__max_features': 6500,\n",
    "#   'tfid__min_df': 5,\n",
    "#   'tfid__ngram_range': (1, 2)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline independent models: LogisticRegression and DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pipe = Pipeline([\n",
    "    ('tfid',TfidfVectorizer(max_df=.325,\n",
    "                           max_features = 6500,\n",
    "                           min_df = 5,\n",
    "                           ngram_range = (1,2))),\n",
    "    ('logit',LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "logit_params = {\n",
    "    'logit__C':loguniform(.01,50),\n",
    "    'logit__penalty':['l2','l1',None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = RandomizedSearchCV(logit_pipe,\n",
    "                  logit_params,\n",
    "                  n_iter = 75,\n",
    "                  n_jobs=-1,\n",
    "                  cv = 3,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('tfid',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=0.325,\n",
       "                                                              max_features=6500,\n",
       "                                                              min_df=5,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words=None,\n",
       "                                                              st...\n",
       "                                                                 solver='liblinear',\n",
       "                                                                 tol=0.0001,\n",
       "                                                                 verbose=0,\n",
       "                                                                 warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=75, n_jobs=-1,\n",
       "                   param_distributions={'logit__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002059E657188>,\n",
       "                                        'logit__penalty': ['l2', 'l1', None]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logit__C': 2.552049865944663, 'logit__penalty': 'l2'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56554307, 0.58988764, 0.57677903, 0.57035647, 0.57973734])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit_model.best_estimator_,X_train,y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5505618 , 0.61797753, 0.61235955, 0.58988764, 0.53370787])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit_model.best_estimator_,X_test,y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2984409480652932"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.score(X_test,y_test) - logit_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2984409480652932"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.best_estimator_.score(X_test,y_test) - logit_model.best_estimator_.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9186656671664168"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.best_estimator_.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6202247191011236"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pipe = Pipeline([\n",
    "    ('tfid',TfidfVectorizer(max_df=.325,\n",
    "                           max_features = 6500,\n",
    "                           min_df = 5,\n",
    "                           ngram_range = (1,2))),\n",
    "    ('tree',DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "tree_params = {\n",
    "    'tree__max_depth':uniform(1,20),\n",
    "    'tree__min_samples_split':uniform(0,.5),\n",
    "    'tree__min_samples_leaf':uniform(0,.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = RandomizedSearchCV(tree_pipe,\n",
    "                  tree_params,\n",
    "                  n_iter = 100,\n",
    "                  n_jobs=-1,\n",
    "                  cv = 3,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('tfid',\n",
       "                                              TfidfVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.float64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=0.325,\n",
       "                                                              max_features=6500,\n",
       "                                                              min_df=5,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              norm='l2',\n",
       "                                                              preprocessor=None,\n",
       "                                                              smooth_idf=True,\n",
       "                                                              stop_words=None,\n",
       "                                                              st...\n",
       "                   param_distributions={'tree__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000205A0068948>,\n",
       "                                        'tree__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000205A1315E08>,\n",
       "                                        'tree__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000020594E673C8>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree__max_depth': 18.788855431067592,\n",
       " 'tree__min_samples_leaf': 0.0064049947690571485,\n",
       " 'tree__min_samples_split': 0.33934451621277056}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47565543, 0.52621723, 0.52059925, 0.50281426, 0.48405253])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(tree_model.best_estimator_,X_train,y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44382022, 0.47752809, 0.52808989, 0.43820225, 0.41573034])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(tree_model.best_estimator_,X_test,y_test, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.057350538214039015"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.score(X_test,y_test) - tree_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.057350538214039015"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.best_estimator_.score(X_test,y_test) - tree_model.best_estimator_.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629685157421289"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.best_estimator_.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5056179775280899"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.best_estimator_.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next step: implement voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Classifier:\n",
    "# LogisticRegression\n",
    "# MultinomialNB\n",
    "# GradientBoostingClassifier\n",
    "# AdaBoostClassifier\n",
    "# RandomForestClassifier\n",
    "# DecisionTreeClassifier\n",
    "# SVC\n",
    "\n",
    "\n",
    "# Pipeline (tfid => Voting Classifier)\n",
    "\n",
    "# Random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.869304461753987"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
